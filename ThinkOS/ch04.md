# ThinkOS Chapter 4

**1. What abstractions do file systems provide?  Give an example of something that is logically true about files systems but not true of their implementations.**

File systems are byte-based, but persistent storage is block-based. So when we work with a file, we treat it as if it were a byte-based system, looking at each individual character as a byte of information. In reality, the OS translates these byte-based operations into block-based operations.

**2. What information do you imagine is stored in an OpenFileTableEntry?**

- Whether the file is open for reading or writing
- File position (how much of the file has been read)
- The next character to read

**3. What are some of the ways operating systems deal with the relatively slow performance of persistent storage?**

Operating systems work to “fill the gap” between main memory performance time and persistent storage performance time. They can do this by: block transfers, prefetching, buffering, and caching.

**4. Suppose your program writes a file and prints a message indicating that it is done writing.  Then a power cut crashes your computer.  After you restore power and reboot the computer, you find that the file you wrote is not there.  What happened?**

The was written into the buffer instead of HDD or SSD storage, likely waiting for a full block of memory before it writes it to nonvolatile memory. Since it was in RAM, as soon as power was cut, the data was lost.

**5. Can you think of one advantage of a File Allocation Table over a UNIX inode?  Or an advantage of a inode over a FAT?**

File Allocation Tables are more scalable than UNIX inodes. With inodes, as files get bigger and bigger, you need to add more indirection blocks that point to even more indirection blocks. A FAT increases linearly in size as you add more pointers.
FAT file systems are more fragile because you have to reference the FAT before accessing any blocks, and if the table is corrupted the whole system could break.

**6. What is overhead?  What is fragmentation?**

Overhead is the space taken up by the data structures used by the allocator (so, the memory used by the thing that allocates memory for everything else).  Fragmentation is unused space caused by blocks that are unused or only partially used.

**7. Why is the "everything is a file" principle a good idea?  Why might it be a bad idea?**

One good thing about it is that it simplifies input/output, since the syntax is the same whether we are reading from a file, from another program’s output, or another data source.  Since “everything is a file”, C behaves the same way no matter what you’re reading from or writing to, and all the programmer has to do is specify the input or output stream.  This adds simplicity and versatility.  Downsides: it changes between OS (like, doesn’t work in Windows).  Also, peripheral devices don’t work this way, so you can’t just redirect output to a printer, and it would require a driver.  It’s also not necessarily accurate (it is an abstraction) and it’s more reasonable to say “everything is a stream of bytes”.

